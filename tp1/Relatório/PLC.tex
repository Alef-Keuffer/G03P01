\documentclass[11pt,a4paper]{report}

\usepackage[portuges]{babel}
\usepackage[utf8]{inputenc} % define o encoding usado texto fonte (input)--usual "utf8" ou "latin1
\usepackage{graphicx} %permite incluir graficos, tabelas, figuras
\usepackage{subcaption}
\usepackage[title]{appendix}
\usepackage{listings}
\usepackage{color}
\usepackage{multicol}
\usepackage{indentfirst}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage[inline]{enumitem}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}

\title{Processamento de Linguagens e Compiladores - Trabalho Prático 1\\
       \textbf{Grupo 3}\\ Relatório
       } %Titulo do documento
%\title{Um Exemplo de Artigo em \LaTeX}
\author{Alef Pinto Keuffer\\ (A91383)\and Catarina Martins Sá Quintas\\ (A91650)\and  Ivo Miguel Gomes Lima \\(A90214)
       } %autores do documento
\date{\today} %data

\begin{document}
	\begin{minipage}{0.9\linewidth}
        \centering
		\includegraphics[width=0.4\textwidth]{um.jpeg}\par\vspace{1cm}
                \href{https://www.uminho.pt/PT}
		{\scshape\LARGE Universidade do Minho} \par
		\vspace{0.6cm}
                \href{https://lcc.di.uminho.pt}
		{\scshape\Large Licenciatura em Ciências da Computação} \par
		\maketitle
	\end{minipage}

\tableofcontents % insere Indice

\chapter{Introdução}

No âmbito da unidade curricular Processamento de Linguagens e compiladores (PLC),
foi-nos proposto a realização de um projeto de forma a aprofundar os nossos
conhecimentos adquiridos na sala de aula, atingindo os seguintes objetivos:

\begin{itemize}
    \item Aumentar a capacidade de escrever Expressões Regulares(ER)
    \item Desenvolver sistematicamente Processadores de Linguagens Regulares, ou Filtros de Texto.
    \item Familiarizar com o módulo 're' presente no Python.
\end{itemize}
  

Para o efeito, criamos um  processador de Bib\TeX \href{http://www.bibtex.org/}. 
A Bib\TeX \ é uma ferramenta de formatação usada em documentos em La\TeX.
Um exemplo desta ferramenta: 
\begin{lstlisting}
@techreport{jspell1,
   author = "J.J. Almeida and Ulisses Pinto",
   title = "Manual de Utilizador do {JSpell}",
   year = 1994,
   type = "Manual",
   month = "Jul",
   institution = "umdi",
   keyword = "morphology, lexical analysis,jspell",
   abstract = {},
   url = "http://natura.di.uminho.pt/~jj/pln/jspellman.ps.gz",
}

\end{lstlisting}

Existe um conjunto de campos obrigatórios e facultativos para que um Bib\TeX \ seja válido, alguns desses campos são: \emph{article}, \emph{book},\emph{inproceedings},\emph{misc},\emph{proceedings} entre outros.



\newpage

\section{Descrição do Problema}
\newcommand{\gv}{\emph{GraphViz}}
\newcommand{\htlm}{\emph{HTML}}
\newcommand{\dott}{\emph{Dot}}
\newcommand{\bib}{Bib\TeX}



A nossa solução deve satisfazer os seguintes requisitos: 
\begin{enumerate}[label=R\arabic*]
\item\label{R1} Fazer a contagem das categorias presentes no documento, tais como: \emph{phDThesis}, \emph{Misc}, \emph{InProceeding }, \emph{etc }.
\item\label{R2}Produzir um documento em formato \htlm \ com
\begin{enumerate*}[label=(R2.\arabic*)]
  \item\label{R21} o nome das categorias encontradas e
  \item\label{R22} respectivas contagens.
\end{enumerate*}
----pergunta 1 
\item\label{R3} Filtrar, para cada entrada de cada categoria, a respetiva
\begin{enumerate*}[label=(R3.\arabic*)]
  \item\label{R31} chave
  \item\label{R32} autores,
  \item\label{R33} e título.
  \item\label{R34} O resultado final deverá ser incluído no documento \htlm \ gerado \ref{R2}.
\end{enumerate*}
-----pergunta 2
\item\label{R4} Criar um índice de autores, que mapeie cada autor nos respectivos registos, de modo a que posteriormente uma ferramenta de procura do Linux possa fazer a pesquisa.
----pergunta 3
\item\label{R5} Construir um Grafo que mostre, para um dado autor (definido à partida) todos os autores que publicam normalmente com o autor em causa.
\item\label{R6}Recorrendo à linguagem \dott \  do \gv, gerar um ficheiro com o grafo de \ref{R5} de modo a que possa, posteriormente, usar uma das ferramentas que processam \dott \  para desenhar o dito grafo de associações de autores.
\end{enumerate}
-----pergunta 4


\section{Estratégia de Resolução}

Nossa estratégia consiste em associar pares de (tipo da publicação, chave) com os campos da entrada e aplicar diversas manipulações sobre essa estrutura para satisfazer os requisitos.

A estratégia para satisfazer \ref{R1} consistiu em ler o arquivo linha a linha verificando se a categoria encontrada já aparecia no dicionário, se já existir, irá ser incrementado o número de ocorrências, senão será adicionado como primeira ocorrência, para que depois possa ser produzido um ficheiro \htlm \ com todas as categorias e o número de ocorrências.

\section{Implementação}


\begin{lstlisting}[language=python]


import re

def main():
    
    file = open("exemplo-utf8.bib", "r")
    read = True
    dic = {}
    string_ls = ['<!DOCTYPE  HTML PUBLIC>\n<HTML>\n   <HEAD>\n      <TITLE>Categories in BibTeX</TITLE>\n   </HEAD>\n   <BODY>']
    while read:
      linhaFicheiro = file.readline()
      ncat = re.match(r'^@(.*){',linhaFicheiro)
      if ncat != None:
        cat_title = ncat.group(1).title()
        dic[cat_title] = dic.get(cat_title,0) + 1
      if not linhaFicheiro:
        read = False
    file.close()

    time = lambda v: 's' if v > 1 else ''

    for k, v in dic.items():
      string_ls.append(f'      <P>The category {k} appears {v} time{time(v)}.</P>')
    string_ls.append(f'   </BODY>\n{prog.test_data_view()}</HTML>')

    with open('output.html','w') as file:
        file.write('\n'.join(string_ls))
\end{lstlisting}

\section{Exemplo}
\section{4.b)}

\begin{lstlisting}[language=python]

import re
import unicodedata

HTML_PROLOGUE = '<!DOCTYPE  html>\n<HTML lang="en">\n<HEAD>\n<meta charset="utf-8">\n      <TITLE>Categories in BibTeX</TITLE>\n <script type="text/x-mathjax-config"> MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}}); </script> <script type="text/javascript" async src="file:////home/useralef/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.6.1/node_modules/@shd101wyy/mume/dependencies/mathjax/MathJax.js" charset="UTF-8"></script>  </HEAD>\n'
HTML_EPILOGUE = '</HTML>'
BIB_EXAMPLE_FILENAME = "exemplo-utf8.bib"
OUTPUT_FILENAME = 'output.html'

#abrir bibtex
def get_bib_str(filename):
    with open(filename,'r') as file:
        return re.sub(r'\b}',r' }',file.read())

#contar e enunciar categorias
def get_pub_type_counts(data):
    pub_types_occur = [x[0] for x in data.keys()]
    pub_types = set(pub_types_occur)
    return [(pub_type, pub_types_occur.count(pub_type)) for pub_type in pub_types]

#copiar todos os dados bib para um dic
def get_entries(string):
    d = {}
    field = re.compile(r'(\w+)\s*=\s*(?:{((?:[^{}]+|{(?:[^{}]+|{[^{}]*})+})+)}|"([^"]+)"|(\d+))')
    for entry in re.finditer(r"@(\w+){(.+),((?:[^{}]+|{(?:[^{}]*|{[^{}]*})+})+)", string):
        d[entry.group(1).lower(), entry.group(2)] = {
            x[0].lower(): get_valid_group(x, 1, 3)
            for x in field.findall(entry.group(3))}
    return d

#Guardar titulo,nome,chave todos os que aparece entre " " ou em {}
def get_valid_group(t, begin_or_group, end_or_group):
    for i in range(begin_or_group, end_or_group + 1):
        if v := t[i]:
            return v

# Retirar {} dentro de {} ou seja {{cenas}} = cenas
def unbrace(expression):
    return expression.translate({ord(x):None for x in '{}'})

#Ordenar autores alfabeticamente para ser mais facil filtrar
def get_author_list(data):
    return sorted(set([a for s in data.values() for a in s.get("author", [])]))

#Por exemplo: da Cruz, Daniela -> Daniela da Cruz
def invert_name(author_name):
    return re.sub(r"([^,]+),\s*([^,]+)", r"\2 \1", author_name)

# Transformar serif, small caps,... 
def remove_latex_special_chars(latex_expression):
    return re.sub(r'\\({|[^{])\b',r'\1',latex_expression)

#Por o <SPAN> ... </Span>
def html_create_span(expression):
    return html_enclose('span',expression)

#Por as <cenas> ... </cenas>
def html_enclose(tag,string):
    return rf'<{tag.upper()}>{string}</{tag.upper()}>'

# Colocar o texto assim https://www.w3schools.com/cssref/tryit.asp?filename=trycss_font-variant
def html_to_small_caps(html_expression):
    return html_add_attr('style','font-variant:small-caps',html_expression)

#colocar o texto assim https://www.w3schools.com/cssref/tryit.asp?filename=trycss_font-family
def html_to_sans_serif(html_expression):
    return html_add_attr('style','font-family:sans-serif',html_expression)

#colocar um atributo exemplos de cima
def html_add_attr(attr,val,html_expression):
    return re.sub(r'<(\w+)([^>]*)\s*>(.*)</\1>',rf'<\1\2 {attr.upper()}="{val}">\3</\1>',html_expression)

# mudifica as entradas colocando mais atributos html
def get_html_pub_type_index(data):
    string_ls = [html_enclose('h2','Publication Type Index')]
    for entry_type in sorted(set(x[0] for x in data)):
        string_ls.append(html_enclose('h3',entry_type))
        for citation_key in [x[1] for x in data if x[0]==entry_type]:
            title = data[entry_type,citation_key].get('title','')
            authors = ', '.join((sorted(data[entry_type,citation_key].get('author',''))))
            string_ls.append(html_enclose('p',f"Key = {citation_key}<br>Title = {fix_title(title)}<br>Autores = {authors}"))
    return '\n'.join(string_ls)

#Processar expressoes matematicas
def str_to_html_math(string):
    return html_add_attr('class','math inline',html_create_span(string))

#faz busca dos atributos que tem de ser mudados enviando para a funcao que as realiza
def fix_title(title):
    substitutions = [(r'\\textsc{((?:\\{|[^{])+)}',lambda m: f'{html_to_small_caps(html_create_span(m.group(1)))}'),
                     (r'\\textsf{((?:\\{|[^{])+)}',lambda m: f'{html_to_sans_serif(html_create_span(m.group(1)))}'),
                     (r'(\$(?:.|\\\$)+\$)', lambda m: f'{str_to_html_math(m.group(1))}')]


    replace = lambda x: mult_replace(x,substitutions)

    return   html_create_span(
             unbrace(
             replace(
             remove_latex_special_chars(
             remove_accents(
             ' '.join(s.strip() for s in title.split('\n')))))))

#Faz a juncao de autores que sao a mesma pessoa
def fix_repeated_authors(data):
    author_blocks = fix_block_func(block_authors_with_two_common_names_v2(get_author_list(data)))
    author_dict = {author_name:max(s,key=len) for s in author_blocks for author_name in s}
    for d in data.values():
        d['author'] = [author_dict[author] for author in d['author']]

# Escolhemos remover acentuacoes e caracteres especiais  que as representam em latex (e.g. "\\~") do nome dos autores.
def format_authors(data):
    for d in data.values():
        if "author" in d:
            author_lst = [ remove_consecutive_spaces(
                           str.strip(
                           invert_name(
                           unbrace(
                           remove_accents(name)))))
                           for name in re.split(r"\band\b", d["author"].replace("\n", " "))]
            d['author'] = [author for author in author_lst if author]


def remove_consecutive_spaces(name):
    return re.sub(r'\s+',' ',name)


def remove_latex_accent(name):
    return re.sub(r'\\\W','',name)

def remove_normal_accent(name):
    return ''.join((c for c in unicodedata.normalize('NFD', name) if unicodedata.category(c) != 'Mn'))

# Recebe um nome normalizado (e.g. Pedro Filipe H. Pereira) e deve retornar "invertido" (e.g. Pereira, P. F. H.)
def last_name_first(name):
    initials =  '. '.join(get_crude_abbrev(name))[:-2]
    last_name = name.split()[-1]
    return f'{last_name}, {initials}'

#Verificar 1 letra autor 1 com 1 letra autor 2 e o mesmo para a segunda
def is_a_first_last_match(author1,author2):
    a1 = get_crude_abbrev(author1)
    a2 = get_crude_abbrev(author2)
    return a1[0] == a2[0] and a1[-1] == a2[-1]

# colocar todos os nomes a maiuscula
def get_crude_abbrev(name):
    return ''.join(c for c in name if c.isupper())

# Verificar se a letra do primeiro autor e igual a 1 letra do sengundo autor e o mesmo para a 2 letra 
def is_a_first_last_match(author1,author2):
    a1 = get_crude_abbrev(author1)
    a2 = get_crude_abbrev(author2)
    return a1[0] == a2[0] and a1[-1] == a2[-1]

# Criar blocos com nomes dos autores, quem estiver no mesmo bloco, e a mesma pessoa.
def block_authors_with_two_common_names_v2(authors):
    res = set()
    for author in authors:
        fs = set()
        for author2 in authors:
            a1 = set(re.findall(r'\w\w+',author))
            a2 = set(re.findall(r'\w\w+',author2))
            if len(a1.intersection(a2)) > 1:
                fs.add(author2)
            elif len(a1) == 1 and len(a1.intersection(a2)) == 1 and is_a_first_last_match(author,author2):
                fs.add(author2)
        res.add(frozenset(fs))
    return res

#Criar transitividade nos autores.  Sem essa funcao, temos blocos {A,B} e {B,C} Depois dessa funcao, vamos ter {A,B,C}
def fix_block_func(data):
    res = set()
    for s1 in data:
        q = s1.copy()
        for s2 in data:
            if s1.intersection(s2) != set():
                q = q.union(s2)
        res.add(frozenset(q))
    return res

def get_html_pub_type_counts(data):
    string_ls = [html_enclose('h2','Number of Occurrences of Publication Types')]
    pub_counts = sorted(get_pub_type_counts(data),key=lambda x: x[1],reverse=True)
    time = lambda v: 's' if v > 1 else ''
    for pub_type, count in pub_counts:
        string_ls.append(html_enclose('p',f'Type {pub_type} appears {count} time{time(count)}'))
    return ''.join(string_ls)

#muda o posicionamento dos nomes atraves de uma lista em regex
def mult_replace(string, replacement_list):
    for old, new in replacement_list:
        string = re.sub(old, new, string)
    return string

\end{lstlisting}
\section{4 c.}
\begin{lstlisting}[language=python]

#faz a juncao de todos os autores no bib para o dicionario aplicando lhe um primeiro filtro
def get_author_index_dict(data):
    index = {}
    for key, e in data.items():
        if 'author' in e:
            for author in e['author']:
                author_name = last_name_first(author)
                if author_name not in index:
                    index[author_name] = set()
                index[author_name].add(key[1])
    return index

#Faz a transformacao de os autores no bib para ficarem no html 4 c
def get_html_author_index(data):
    index = sorted(get_author_index_dict(data).items())
    alphabet_order = sorted(set(c[0][0] for c in index))
    string_ls = [html_enclose('h2','Author Index')]
    i = 0
    string_ls.append(html_enclose('h3',alphabet_order[i]))
    for author,citation_keys in index:
        if author[0] != alphabet_order[i]:
            i += 1
            string_ls.append(html_enclose('h3',alphabet_order[i]))
        citation_keys_str = ', '.join(citation_keys)
        string_ls.append(html_enclose('p',f'{author}, {citation_keys_str}'))
    return ''.join(string_ls)
\end{lstlisting}
\section{4 d.}
\begin{lstlisting}[language=python]
import os
import textwrap

def get_author_pub_graph(author,data):
    pub_partners = []
    for entry in data.values():
        if 'author' in entry and author in entry['author']:
            for partner in entry['author']:
                if partner != author:
                    pub_partners.append(partner)
    return [(author_name,pub_partners.count(author_name))
            for author_name in set(pub_partners)]


def get_dot_graph(author,data):
    g = sorted(get_author_pub_graph(author,data),key = lambda x: x[1])
    string_ls = ['graph{']
    string_ls2 = []
    for partner_author,no_joint_pub in g[-3:]:
        string_ls2.append(f'"{author}" -- "{partner_author}" [label="{no_joint_pub}"]')
    string_ls.append(textwrap.indent('\n'.join(string_ls2),'  '))
    string_ls.append('}')
    return '\n'.join(string_ls)

def get_html_dot_svg(author,data):
    DOT_INPUT_FILENAME = 'dot_input'
    with open(DOT_INPUT_FILENAME,'w') as file:
        file.write(get_dot_graph(author,data))
    os.system(f'dot -T svg -O {DOT_INPUT_FILENAME}')
    with open(DOT_INPUT_FILENAME + '.svg','r') as file:
        return re.search(r'<svg(?:.|\n)+</svg>',file.read()).group()

def get_html_common_pub_author(author,data):
    string_ls = [html_enclose('h2','Author Graph')]
    string_ls.append(get_html_dot_svg(author,data))
    return ''.join(string_ls)

def solve(author_name,INPUT_FILENAME=BIB_EXAMPLE_FILENAME):
    html_str_ls = [HTML_PROLOGUE]
    bib_str = get_bib_str(INPUT_FILENAME)

    entries = get_entries(bib_str)
    format_authors(entries)
    fix_repeated_authors(entries)

    html_str_ls.append(html_enclose('body',f'{get_html_pub_type_counts(entries)}{get_html_common_pub_author(author_name,entries)}{get_html_pub_type_index(entries)}{get_html_author_index(entries)}'))

    html_str_ls.append(HTML_EPILOGUE)

    with open(OUTPUT_FILENAME,'w') as file:
        file.write('\n'.join(html_str_ls))

    solve(author_name,filename)

\end{lstlisting}

\chapter{Conclusão}

\appendix
\begin{appendices}
\chapter{Código}


\begin{lstlisting}[language=python]
import re
import sys
import os
import os.path
import unicodedata

HTML_PROLOGUE = '<!DOCTYPE  html>\n<HTML lang="en">\n<HEAD>\n<meta charset="utf-8">\n      <TITLE>Categories in BibTeX</TITLE>\n <script type="text/x-mathjax-config"> MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}}); </script> <script type="text/javascript" async src="file:////home/useralef/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.6.1/node_modules/@shd101wyy/mume/dependencies/mathjax/MathJax.js" charset="UTF-8"></script>  </HEAD>\n'
HTML_EPILOGUE = '</HTML>'
BIB_EXAMPLE_FILENAME = "exemplo-utf8.bib"
OUTPUT_FILENAME = 'output.html'

def get_bib_str(filename):
    with open(filename,'r') as file:
        return re.sub(r'\b}$',r' }',file.read())

def get_pub_type_counts(data):
    pub_types_occur = [x[0] for x in data.keys()]
    pub_types = set(pub_types_occur)
    return [(pub_type, pub_types_occur.count(pub_type)) for pub_type in pub_types]

def get_entries(string):
     d = {}
    field = re.compile(r'(\w+)\s*=\s*(?:{((?:[^{}]+|{(?:[^{}]+|{[^{}]*})+})+)}|"([^"]+)"|(\d+))')
    for entry in re.finditer(r"@(\w+){(.+),((?:[^{}]+|{(?:[^{}]*|{[^{}]*})+})+)", string):
        d[entry.group(1).lower(), entry.group(2)] = {
            x[0].lower(): get_valid_group(x, 1, 3)
            for x in field.findall(entry.group(3))}
    return d

def get_valid_group(t, begin_or_group, end_or_group):
    for i in range(begin_or_group, end_or_group + 1):
        if v := t[i]:
            return v

def unbrace(expression):
    return expression.translate({ord(x):None for x in '{}'})


def get_author_list(data):
    return sorted(set([a for s in data.values() for a in s.get("author", [])]))

def invert_name(author_name):
    return re.sub(r"([^,]+),\s*([^,]+)", r"\2 \1", author_name)

def remove_latex_special_chars(latex_expression):
    return re.sub(r'\\({|[^{])\b',r'\1',latex_expression)

def str_to_html_small_caps(expression):
    return html_to_small_caps(html_create_span(expression))

def html_create_span(expression):
    return html_enclose('span',expression)

def html_enclose(tag,string):
    return rf'<{tag.upper()}>{string}</{tag.upper()}>'

def html_to_small_caps(html_expression):
    return html_add_attr('style','font-variant:small-caps',html_expression)

def html_to_sans_serif(html_expression):
    return html_add_attr('style','font-family:sans-serif',html_expression)

def html_add_attr(attr,val,html_expression):
    return re.sub(r'<(\w+)([^>]*)\s*>(.*)</\1>',rf'<\1\2 {attr.upper()}="{val}">\3</\1>',html_expression)

def get_html_pub_type_index(data):
    string_ls = [html_enclose('h2','Publication Type Index')]
    for entry_type in sorted(set(x[0] for x in data)):
        string_ls.append(html_enclose('h3',entry_type))
        for citation_key in [x[1] for x in data if x[0]==entry_type]:
            title = data[entry_type,citation_key].get('title','')
            authors = ', '.join((sorted(data[entry_type,citation_key].get('author',''))))
            string_ls.append(html_enclose('p',f"Key = {citation_key}<br>Title = {fix_title(title)}<br>Autores = {authors}"))
    return '\n'.join(string_ls)

def str_to_html_math(string):
    return html_add_attr('class','math inline',html_create_span(string))

def fix_title(title):
    substitutions = [(r'\\textsc{((?:\\{|[^{])+)}',lambda m: f'{html_to_small_caps(html_create_span(m.group(1)))}'),
                     (r'\\textsf{((?:\\{|[^{])+)}',lambda m: f'{html_to_sans_serif(html_create_span(m.group(1)))}'),
                     (r'(\$(?:.|\\\$)+\$)', lambda m: f'{str_to_html_math(m.group(1))}')]


    replace = lambda x: mult_replace(x,substitutions)

    return   html_create_span(
             unbrace(
             replace(
             remove_latex_special_chars(
             ' '.join(s.strip() for s in title.split('\n'))))))


def mult_replace(string, replacement_list):
    for old, new in replacement_list:
        string = re.sub(old, new, string)
    return string

def fix_repeated_authors(data):
    author_blocks = fix_block_func(block_authors_with_two_common_names_v2(get_author_list(data)))
    author_dict = {author_name:max(s,key=len) for s in author_blocks for author_name in s}
    for d in data.values():
        d['author'] = [author_dict[author] for author in d['author']]

def format_authors(data):
    for d in data.values():
        if "author" in d:
            author_lst = [ remove_consecutive_spaces(
                           str.strip(
                           invert_name(
                           unbrace(
                           remove_accents(name)))))
                           for name in re.split(r"\band\b", d["author"].replace("\n", " "))]
            d['author'] = [author for author in author_lst if author]


def remove_consecutive_spaces(name):
    return re.sub(r'\s+',' ',name)

def remove_accents(name):
    return remove_latex_accent(remove_normal_accent(name))

def remove_latex_accent(name):
    return re.sub(r'\\\W','',name)

def remove_normal_accent(name):
    return ''.join((c for c in unicodedata.normalize('NFD', name) if unicodedata.category(c) != 'Mn'))

def last_name_first(name):
    initials =  '. '.join(get_crude_abbrev(name))[:-2]
    last_name = name.split()[-1]
    return f'{last_name}, {initials}'


def get_author_index_dict(data):
    index = {}
    for key, e in data.items():
        if 'author' in e:
            for author in e['author']:
                author_name = last_name_first(author)
                if author_name not in index:
                    index[author_name] = set()
                index[author_name].add(key[1])
    return index

def get_author_pub_graph(author,data):
    pub_partners = []
    for entry in data.values():
        if 'author' in entry and author in entry['author']:
            for partner in entry['author']:
                if partner != author:
                    pub_partners.append(partner)
    return [(author_name,pub_partners.count(author_name))
            for author_name in set(pub_partners)]

def get_html_author_index(data):
    index = sorted(get_author_index_dict(data).items())
    alphabet_order = sorted(set(c[0][0] for c in index))
    string_ls = [html_enclose('h2','Author Index')]
    i = 0
    string_ls.append(html_enclose('h3',alphabet_order[i]))
    for author,citation_keys in index:
        if author[0] != alphabet_order[i]:
            i += 1
            string_ls.append(html_enclose('h3',alphabet_order[i]))
        citation_keys_str = ', '.join(citation_keys)
        string_ls.append(html_enclose('p',f'{author}, {citation_keys_str}'))
    return ''.join(string_ls)


def get_crude_abbrev(name):
    return ''.join(c for c in name if c.isupper())


def is_a_first_last_match(author1,author2):
    a1 = get_crude_abbrev(author1)
    a2 = get_crude_abbrev(author2)
    return a1[0] == a2[0] and a1[-1] == a2[-1]

def block_authors_with_two_common_names(authors):
    res = set()
    for author in authors:
        fs = set()
        for author2 in authors:
            if len(set(re.findall(r'\w\w+',author)).intersection(re.findall(r'\w\w+',author2))) > 1:
                fs.add(author2)
        if not fs:
            print(author)
        res.add(frozenset(fs))
    return res

def block_authors_with_two_common_names_v2(authors):
    res = set()
    for author in authors:
        fs = set()
        for author2 in authors:
            a1 = set(re.findall(r'\w\w+',author))
            a2 = set(re.findall(r'\w\w+',author2))
            if len(a1.intersection(a2)) > 1:
                fs.add(author2)
            elif len(a1) == 1 and len(a1.intersection(a2)) == 1 and is_a_first_last_match(author,author2):
                fs.add(author2)
        res.add(frozenset(fs))
    return res

def fix_block_func(data):
    res = set()
    for s1 in data:
        q = s1.copy()
        for s2 in data:
            if s1.intersection(s2) != set():
                q = q.union(s2)
        res.add(frozenset(q))
    return res


def get_dot_graph(author,data):
    import textwrap
    g = sorted(get_author_pub_graph(author,data),key = lambda x: x[1])
    string_ls = ['graph{']
    string_ls2 = []
    for partner_author,no_joint_pub in g[-3:]:
        string_ls2.append(f'"{author}" -- "{partner_author}" [label="{no_joint_pub}"]')
    string_ls.append(textwrap.indent('\n'.join(string_ls2),'  '))
    string_ls.append('}')
    return '\n'.join(string_ls)


def get_html_pub_type_counts(data):
    string_ls = [html_enclose('h2','Number of Occurrences of Publication Types')]
    pub_counts = sorted(get_pub_type_counts(data),key=lambda x: x[1],reverse=True)
    time = lambda v: 's' if v > 1 else ''
    for pub_type, count in pub_counts:
        string_ls.append(html_enclose('p',f'Type {pub_type} appears {count} time{time(count)}'))
    return ''.join(string_ls)

def get_html_dot_svg(author,data):
    DOT_INPUT_FILENAME = 'dot_input'
    with open(DOT_INPUT_FILENAME,'w') as file:
        file.write(get_dot_graph(author,data))
    os.system(f'dot -T svg -O {DOT_INPUT_FILENAME}')
    with open(DOT_INPUT_FILENAME + '.svg','r') as file:
        return re.search(r'<svg(?:.|\n)+</svg>',file.read()).group()


def get_html_common_pub_author(author,data):
    string_ls = [html_enclose('h2','Author Graph')]
    string_ls.append(get_html_dot_svg(author,data))
    return ''.join(string_ls)

def solve(author_name,INPUT_FILENAME=BIB_EXAMPLE_FILENAME):
    html_str_ls = [HTML_PROLOGUE]
    bib_str = get_bib_str(INPUT_FILENAME)

    entries = get_entries(bib_str)
    format_authors(entries)
    fix_repeated_authors(entries)

    html_str_ls.append(html_enclose('body',f'{get_html_pub_type_counts(entries)}{get_html_common_pub_author(author_name,entries)}{get_html_pub_type_index(entries)}{get_html_author_index(entries)}'))

    html_str_ls.append(HTML_EPILOGUE)

    with open(OUTPUT_FILENAME,'w') as file:
        file.write('\n'.join(html_str_ls))

if __name__ == '__main__':
    filename = sys.argv[1]
    assert os.path.isfile(sys.argv[1])
    if len(sys.argv) < 3:
        author_name = 'Daniela da Cruz'
    else:
        author_name = sys.argv[2]
    solve(author_name,filename)
\end{lstlisting}
\end{appendices} 

\end{document}